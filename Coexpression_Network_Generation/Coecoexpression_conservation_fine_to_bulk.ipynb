{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import h5py\n",
    "import CococoNet_reader\n",
    "import numpy as np\n",
    "import anndata\n",
    "import pickle\n",
    "import tqdm\n",
    "import Go_annotations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sc.settings.verbosity = 3  \n",
    "sc.set_figure_params(facecolor = 'white', figsize = (10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, sparse\n",
    "import bottleneck\n",
    "\n",
    "\n",
    "def run_egad(go, nw, **kwargs):\n",
    "    \"\"\"EGAD running function\n",
    "    \n",
    "    Wrapper to lower level functions for EGAD\n",
    "\n",
    "    EGAD measures modularity of gene lists in co-expression networks. \n",
    "\n",
    "    This was translated from the MATLAB version, which does tiled Cross Validation\n",
    "    \n",
    "    The useful kwargs are:\n",
    "    int - nFold : Number of CV folds to do, default is 3, \n",
    "    int - {min,max}_count : limits for number of terms in each gene list, these are exclusive values\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "        go {pd.DataFrame} -- dataframe of genes x terms of values [0,1], where 1 is included in gene lists\n",
    "        nw {pd.DataFrame} -- dataframe of co-expression network, genes x genes\n",
    "        **kwargs \n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame -- dataframe of terms x metrics where the metrics are \n",
    "        ['AUC', 'AVG_NODE_DEGREE', 'DEGREE_NULL_AUC', 'P_Value']\n",
    "    \"\"\"\n",
    "    assert nw.shape[0] == nw.shape[1] , 'Network is not square'\n",
    "    assert np.all(nw.index == nw.columns) , 'Network index and columns are not in the same order'\n",
    "    nw_mask = nw.isna().sum(axis=1) != nw.shape[1]\n",
    "    nw = nw.loc[nw_mask, nw_mask].astype(float)\n",
    "    np.fill_diagonal(nw.values, 1)\n",
    "    return _runNV(go, nw, **kwargs)\n",
    "\n",
    "\n",
    "def _runNV(go, nw, nFold=3, min_count=20, max_count=1000):\n",
    "\n",
    "    #Make sure genes are same in go and nw\n",
    "    genes_intersect = go.index.intersection(nw.index)\n",
    "\n",
    "    go = go.loc[genes_intersect, :]\n",
    "    nw = nw.loc[genes_intersect, genes_intersect]\n",
    "\n",
    "    #Make sure there aren't duplicates\n",
    "    duplicates = nw.index.duplicated(keep='first')\n",
    "    nw = nw.loc[~duplicates, ~duplicates]\n",
    "\n",
    "    go = go.loc[:, (go.sum(axis=0) > min_count) & (go.sum(axis=0) < max_count)]\n",
    "    go = go.loc[~go.index.duplicated(keep='first'), :]\n",
    "\n",
    "    roc = _new_egad(go.values, nw.values, nFold)\n",
    "\n",
    "    col_names = ['AUC', 'AVG_NODE_DEGREE', 'DEGREE_NULL_AUC', 'P_Value']\n",
    "    #Put output in dataframe\n",
    "    return pd.DataFrame(dict(zip(col_names, roc)), index=go.columns)\n",
    "\n",
    "\n",
    "def _new_egad(go, nw, nFold):\n",
    "\n",
    "    #Build Cross validated Positive\n",
    "    x, y = np.where(go)\n",
    "    cvgo = {}\n",
    "    for i in np.arange(nFold):\n",
    "        a = x[i::nFold]\n",
    "        b = y[i::nFold]\n",
    "        dat = np.ones_like(a)\n",
    "        mask = sparse.coo_matrix((dat, (a, b)), shape=go.shape)\n",
    "        cvgo[i] = go - mask.toarray()\n",
    "        \n",
    "    CVgo = np.concatenate(list(cvgo.values()), axis=1)\n",
    "\n",
    "    sumin = np.matmul(nw.T, CVgo)\n",
    "\n",
    "    degree = np.sum(nw, axis=0)\n",
    "\n",
    "    predicts = sumin / degree[:, None]\n",
    "\n",
    "    np.place(predicts, CVgo > 0, np.nan)\n",
    "\n",
    "    #Calculate ranks of positives\n",
    "    rank_abs = lambda x: stats.rankdata(np.abs(x))\n",
    "    predicts2 = np.apply_along_axis(rank_abs, 0, predicts)\n",
    "\n",
    "    #Masking Nans that were ranked (how tiedrank works in matlab)\n",
    "    predicts2[np.isnan(predicts)] = np.nan\n",
    "\n",
    "    filtering = np.tile(go, nFold)\n",
    "\n",
    "    #negatives :filtering == 0\n",
    "    #Sets Ranks of negatives to 0\n",
    "    np.place(predicts2, filtering == 0, 0)\n",
    "\n",
    "    #Sum of ranks for each prediction\n",
    "    p = bottleneck.nansum(predicts2, axis=0)\n",
    "\n",
    "    #Number of predictions\n",
    "    #Number of 1's masked for each GO term for each CV\n",
    "    n_p = np.sum(filtering, axis=0) - np.sum(CVgo, axis=0)\n",
    "\n",
    "    #Number of negatives\n",
    "    #Number of GO terms - number of postiive\n",
    "    n_n = filtering.shape[0] - np.sum(filtering, axis=0)\n",
    "\n",
    "    roc = (p / n_p - (n_p + 1) / 2) / n_n\n",
    "    U = roc * n_p * n_n\n",
    "    Z = (np.abs(U - (n_p * n_n / 2))) / np.sqrt(n_p * n_n *\n",
    "                                                (n_p + n_n + 1) / 12)\n",
    "    roc = roc.reshape(nFold, go.shape[1])\n",
    "    Z = Z.reshape(nFold, go.shape[1])\n",
    "    #Stouffer Z method\n",
    "    Z = bottleneck.nansum(Z, axis=0) / np.sqrt(nFold)\n",
    "    #Calc ROC of Neighbor Voting\n",
    "    roc = bottleneck.nanmean(roc, axis=0)\n",
    "    P = stats.norm.sf(Z)\n",
    "\n",
    "    #Average degree for nodes in each go term\n",
    "    avg_degree = degree.dot(go) / np.sum(go, axis=0)\n",
    "\n",
    "    #Calc null auc for degree\n",
    "    ranks = np.tile(stats.rankdata(degree), (go.shape[1], 1)).T\n",
    "\n",
    "    np.place(ranks, go == 0, 0)\n",
    "\n",
    "    n_p = bottleneck.nansum(go, axis=0)\n",
    "    nn = go.shape[0] - n_p\n",
    "    p = bottleneck.nansum(ranks, axis=0)\n",
    "\n",
    "    roc_null = (p / n_p - ((n_p + 1) / 2)) / nn\n",
    "\n",
    "    return roc, avg_degree, roc_null, P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_h5py = h5py.File('/data/passala/Data_from_CoCoCoNet/single_cell_data/Ara_data.hdf5','r')\n",
    "list(single_cell_h5py.keys())\n",
    "col_data = single_cell_h5py['coldata']\n",
    "row_data = single_cell_h5py['rowdata']\n",
    "embedding_data = single_cell_h5py['embedding']\n",
    "normalized_counts = single_cell_h5py['normalized_counts']\n",
    "\n",
    "row_data_decoded = []\n",
    "\n",
    "for gene_name in row_data:\n",
    "    row_data_decoded.append(gene_name[0].decode())\n",
    "\n",
    "cell_type_number =[]\n",
    "study_number = []\n",
    "study_id = []\n",
    "batch_cluster = []\n",
    "meta_cluster = []\n",
    "umap_coordinates = []\n",
    "\n",
    "for cell_identity in col_data:\n",
    "    cell_type_number.append(cell_identity[0])  \n",
    "    study_number.append(cell_identity[1])\n",
    "    study_id.append(cell_identity[2])\n",
    "    batch_cluster.append(cell_identity[3])\n",
    "    meta_cluster.append(cell_identity[4])\n",
    "\n",
    "barcode_for_each_cell = [] \n",
    "for barcode in embedding_data:\n",
    "    barcode_for_each_cell.append(barcode[2])\n",
    "    current_umap_coordinates =[barcode[1],barcode[0]]\n",
    "    umap_coordinates.append(current_umap_coordinates)\n",
    "umap_coordinates = np.array(umap_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1100828/2112258600.py:4: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  single_cell_arabidopsis_root_4_datasets = anndata.AnnData(X = normalized_counts[:],obs = obs_arabidop, var = vars_arabidop)\n"
     ]
    }
   ],
   "source": [
    "obs_arabidop = pd.DataFrame(index = barcode_for_each_cell, data = list(zip(cell_type_number,study_number,batch_cluster, meta_cluster)), columns = ['Cell Type','Study Number','Batch Cluster','Meta Cluster'] )\n",
    "\n",
    "vars_arabidop = pd.DataFrame(index = row_data_decoded)\n",
    "single_cell_arabidopsis_root_4_datasets = anndata.AnnData(X = normalized_counts[:],obs = obs_arabidop, var = vars_arabidop)\n",
    "single_cell_arabidopsis_root_4_datasets.obsm['X_umap'] = umap_coordinates\n",
    "umap_df = pd.DataFrame(data = single_cell_arabidopsis_root_4_datasets.obsm['X_umap'], columns = ['Axis 1','Axis 2'], index = barcode_for_each_cell)\n",
    "bad_values = umap_df.sort_values(by = 'Axis 1', ascending = False).head(6).index\n",
    "single_cell_arabidopsis_root_4_datasets.obs.loc[bad_values]\n",
    "good_obs = single_cell_arabidopsis_root_4_datasets.obs.loc[~single_cell_arabidopsis_root_4_datasets.obs.index.isin(bad_values)]\n",
    "single_cell_arabidopsis_root_4_datasets  = single_cell_arabidopsis_root_4_datasets[good_obs.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1100828/1255668264.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  single_cell_arabidopsis_root_4_datasets.obs['Meta Cluster String'] =single_cell_arabidopsis_root_4_datasets.obs['Meta Cluster'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "single_cell_arabidopsis_root_4_datasets.obs['Meta Cluster String'] =single_cell_arabidopsis_root_4_datasets.obs['Meta Cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered out 1196 genes that are detected in less than 10 cells\n"
     ]
    }
   ],
   "source": [
    "sc.pp.filter_cells(single_cell_arabidopsis_root_4_datasets, min_genes=300)\n",
    "sc.pp.filter_genes(single_cell_arabidopsis_root_4_datasets, min_cells=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting highly variable genes\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(single_cell_arabidopsis_root_4_datasets, min_mean=0.125, max_mean=4, min_disp=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(single_cell_arabidopsis_root_4_datasets, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.highly_variable_genes(single_cell_arabidopsis_root_4_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(single_cell_arabidopsis_root_4_datasets, svd_solver='arpack', random_state=303)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(single_cell_arabidopsis_root_4_datasets, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(single_cell_arabidopsis_root_4_datasets, n_neighbors=12, n_pcs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(single_cell_arabidopsis_root_4_datasets, random_state = 233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(single_cell_arabidopsis_root_4_datasets,color = 'Meta Cluster String', s = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(single_cell_arabidopsis_root_4_datasets,resolution = 15, random_state = 325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_arabidopsis_root_4_datasets.obs['leiden'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_arabidopsis_root_4_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_arabidopsis_root_4_datasets = single_cell_arabidopsis_root_4_datasets[:,single_cell_arabidopsis_root_4_datasets.var['means']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psuedobulk_df = pd.DataFrame(index = single_cell_arabidopsis_root_4_datasets.var_names)\n",
    "all_samples = list(single_cell_arabidopsis_root_4_datasets.obs.leiden.unique()) # Generate list of all combinations of the above ## Make a base dataframe index we will add stuff on to later\n",
    "psuedobulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_type in all_samples:\n",
    "\n",
    "    ## Read in the Names so our code is easy to understand\n",
    "    current_cluster = batch_type\n",
    "\n",
    "    ## Calculate the Psuedobulked mean\n",
    "    cells_matching_batch_and_cluster = single_cell_arabidopsis_root_4_datasets[single_cell_arabidopsis_root_4_datasets.obs['leiden'] == current_cluster ]\n",
    "    mean_of_genes = cells_matching_batch_and_cluster.X.mean(axis = 0).tolist()\n",
    "\n",
    "\n",
    "    name_of_combo = current_cluster\n",
    "    psuedobulk_df[name_of_combo] = mean_of_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psuedobulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = psuedobulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sci\n",
    "\n",
    "rank_test_py_exp = sci.rankdata(exp_data, method = 'average', axis = 1)                #Row ranks\n",
    "rank_test_py_exp = rank_test_py_exp - rank_test_py_exp.mean(axis = 1)[1]               #Center each gene, subtract mean rank\n",
    "rank_test_py_exp_2 = np.square(rank_test_py_exp)                                       #Square\n",
    "rank_test_py_exp = rank_test_py_exp /np.sqrt(rank_test_py_exp_2.sum(axis = 1))[:,None] #divide by sqrt(rowSums)\n",
    "cr_python = np.dot(rank_test_py_exp, rank_test_py_exp.T)                               # Get correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results = pd.DataFrame(columns = psuedobulk_df.index, index = psuedobulk_df.index, data = cr_python)\n",
    "corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabi_net = CococoNet_reader.read_cococonet('arabidopsis')\n",
    "arabi_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabi_net_col_trimmed = arabi_net[arabi_net.columns.intersection(corr_results.index)]\n",
    "arabi_net_both_trimmed = arabi_net_col_trimmed.loc[arabi_net_col_trimmed.index.isin(corr_results.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabi_net_both_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results_col_trimmed = corr_results[corr_results.columns.intersection(arabi_net_both_trimmed.index)]\n",
    "corr_results_both_trimmed = corr_results_col_trimmed.loc[corr_results_col_trimmed.index.isin(arabi_net_both_trimmed.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results_both_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results_both_trimmed = corr_results_both_trimmed.clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_results_both_trimmed = corr_results_both_trimmed[arabi_net_both_trimmed.columns]\n",
    "corr_results_both_trimmed = corr_results_both_trimmed.T\n",
    "corr_results_both_trimmed = corr_results_both_trimmed[arabi_net_both_trimmed.columns]\n",
    "corr_results_both_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# sns.clustermap(corr_results_both_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# sns.clustermap(arabi_net_both_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabi_net_both_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trim cococonets to match\n",
    "\n",
    "\n",
    "arab_cococonet_1_set_to_zero = arabi_net_both_trimmed.replace(1,0)\n",
    "corr_results_both_trimmed = corr_results_both_trimmed.replace(1,0)\n",
    "\n",
    "\n",
    "top_10_arab_genes = np.array(\n",
    "    [arab_cococonet_1_set_to_zero[c].nlargest(10).index.values for c in arab_cococonet_1_set_to_zero]\n",
    ")  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "top_10_arab_genes_dataframe = pd.DataFrame(\n",
    "    data=top_10_arab_genes,\n",
    "    index=arab_cococonet_1_set_to_zero.index,\n",
    "    columns=[\n",
    "        \"One\",\n",
    "        \"Two\",\n",
    "        \"Three\",\n",
    "        \"Four\",\n",
    "        \"Five\",\n",
    "        \"Six\",\n",
    "        \"Seven\",\n",
    "        \"Eight\",\n",
    "        \"Nine\",\n",
    "        \"Ten\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "tidy_top_10 = top_10_arab_genes_dataframe.melt(ignore_index= False)\n",
    "\n",
    "zipped_pairs = zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))\n",
    "\n",
    "binary_masked_cococonet = pd.DataFrame(data = 0, columns = arab_cococonet_1_set_to_zero.columns, index = arab_cococonet_1_set_to_zero.index)\n",
    "#binary_masked_cococonet.loc[zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))] = 1\n",
    "#binary_masked_cococonet.sum(axis =0)\n",
    "for row,column in zipped_pairs:\n",
    "    binary_masked_cococonet.at[row,column] = 1\n",
    "\n",
    "binary_masked_cococonet\n",
    "\n",
    "ranked_columns_cococonet = corr_results_both_trimmed.rank()\n",
    "dot_product_cococonet = binary_masked_cococonet.dot(ranked_columns_cococonet)\n",
    "subtract_minimum = dot_product_cococonet-65 # This is 11+10+9+8+7+6+5+4+3+2\n",
    "subtract_minimum\n",
    "function_conservations_scores = subtract_minimum/(subtract_minimum.max().max() - subtract_minimum.min().min())\n",
    "function_conservations_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranked_function_conservation_scores = function_conservations_scores.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_ranked_function_conservation_scores = ranked_function_conservation_scores/19211\n",
    "# normalized_ranked_function_conservation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(function_conservations_scores)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.diag(function_conservations_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ax = sns.histplot(np.diag(function_conservations_scores))\n",
    " ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Single_cell_data_fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
